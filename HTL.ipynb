{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HwBjk3KIrEq"
      },
      "source": [
        "# 1. Load Python Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys2yIuIqIoaL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import shap\n",
        "\n",
        "import sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, PowerTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import PredictionErrorDisplay\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import keras_tuner as kt\n",
        "\n",
        "import xgboost\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-iZWfTzyB4T"
      },
      "source": [
        "# 2. Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "i8fxB6HZyLGj",
        "outputId": "92f51d5c-74ac-48a5-e65e-78eaf599fd84"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('Data.xlsx')\n",
        "data = data.filter(regex='^(?!Unnamed)')\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5btL2t7Kbyf"
      },
      "source": [
        "# 3. Data Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM2b4IVZExrO"
      },
      "source": [
        "### Add Cellulose and Hemicellulose to Carbohydrate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "G8cWzhooE_k5",
        "outputId": "abad03bd-0186-4b7d-9b2e-e2b11426863f"
      },
      "outputs": [],
      "source": [
        "for i in range(data.shape[0]):\n",
        "  if np.isnan(data.loc[i, 'Carbohydrates wt%']) and not np.isnan(data.loc[i, 'Cellulose wt%']) and not np.isnan(data.loc[i, 'Hemicellulose wt%']):\n",
        "    data.loc[i, 'Carbohydrates wt%'] = data.loc[i, 'Cellulose wt%'] + data.loc[i, 'Hemicellulose wt%']\n",
        "data[['Carbohydrates wt%', 'Cellulose wt%', 'Hemicellulose wt%']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Multiply Nitrogen by 6.25 to Obtain Protein"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i in range(data.shape[0]):\n",
        "#   if data.loc[i, 'Feedstock Type'] in ['Woody Biomass', 'Algae', 'Food Waste', 'Household/Kitchen Waste'] and np.isnan(data.loc[i, 'Protein wt%']) and not np.isnan(data.loc[i, 'N%']):\n",
        "#     data.loc[i, 'Protein wt%'] = data.loc[i, 'N%']*6.25\n",
        "# data[['Protein wt%']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3FJIMtxLoMX"
      },
      "source": [
        "### Replace Categorical Values with Numerical Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "udwu_4nIL1-N",
        "outputId": "3a6ba002-2581-4943-aae3-78358a54fda4"
      },
      "outputs": [],
      "source": [
        "# Feedstock type:\n",
        "# Woody Biomass = 0\n",
        "# Algae = 1\n",
        "# Model Compounds = 2\n",
        "# Food Waste = 3\n",
        "# Human Waste = 4\n",
        "# Household/Kitchen Waste = 5\n",
        "# Municipal Solid Waste = 6\n",
        "# Animal Manure = 7\n",
        "# Others = 8\n",
        "\n",
        "# Pre-processing:\n",
        "# No = 0\n",
        "# Yes = 1\n",
        "\n",
        "# Reactor Type:\n",
        "# Batch/Autoclave = 0\n",
        "# Plug Flow Reactor (PFR) = 1\n",
        "# Continuous Stirred-Tank Reactor (CSTR) = 2\n",
        "\n",
        "# Catalyst:\n",
        "# No Catalyst = 0\n",
        "# Uses Catalyst = 1\n",
        "\n",
        "# Solvent:\n",
        "# No Solvent = 0\n",
        "# Uses Solvent = 1\n",
        "\n",
        "data['Feedstock Type'].replace({'Woody Biomass': 0, 'Algae': 1, 'Model Compounds': 2, 'Food Waste': 3, 'Human Waste': 4, 'Household/Kitchen Waste': 5, 'Municipal Solid Waste': 6, 'Animal Manure': 7, 'Others': 8}, inplace = True)\n",
        "data['Pre-processing'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
        "data['Reactor Type'].replace({'Batch/Autoclave': 0, 'Plug Flow Reactor (PFR)': 1, 'Continuous Stirred-Tank Reactor (CSTR)': 2}, inplace = True)\n",
        "data['Catalyst'] = data['Catalyst'].notna().astype(int)\n",
        "data['Solvent'] = data['Solvent'].notna().astype(int)\n",
        "\n",
        "data[['Feedstock Type', 'Pre-processing', 'Reactor Type', 'Catalyst', 'Solvent']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Drop Abnormal Datapoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Number of NaN biocrude values: ', data['Biocrude wt%'].isna().sum())\n",
        "print('Number of \"0\" biocrude values: ', pd.Series(data['Biocrude wt%'] == 0).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data[data['Biocrude wt%'].notna()]\n",
        "data = data[data['Biocrude wt%'] != 0]\n",
        "data[['Biocrude wt%']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mk3GclIB6lSd"
      },
      "source": [
        "### Show Missing Missing Percentages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w44ADVcNTULo",
        "outputId": "666048fa-e3b1-4dca-eac3-7a4fc73dfff7"
      },
      "outputs": [],
      "source": [
        "missing = data.isna().sum()/data.shape[0]*100\n",
        "missing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGTbPTAQ6tzP"
      },
      "source": [
        "### Drop Columns with Too Many Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "vzPH3oYo5EFo",
        "outputId": "ab538632-32e4-4085-bf04-afbd3fdefb27"
      },
      "outputs": [],
      "source": [
        "# Maintain original dataset\n",
        "original_data = data\n",
        "\n",
        "threshold = 0.3\n",
        "min_count = int((1 - threshold) * len(data))\n",
        "data = data.loc[:, data.notna().sum() >= min_count]\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm4fy2FGkQ9u"
      },
      "source": [
        "### Replace NaN with Mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "iL6hd540kWLB",
        "outputId": "faf93e1f-d7b1-4492-f2b5-ac51d4cf6c72"
      },
      "outputs": [],
      "source": [
        "imp = SimpleImputer()\n",
        "imp.set_output(transform = 'pandas')\n",
        "data = imp.fit_transform(data)\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QiuhBaP7Hz-"
      },
      "source": [
        "### Split into Input/Output Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgJXMwyx_sUn"
      },
      "outputs": [],
      "source": [
        "# X = input = all columns up to (and including) Solvent\n",
        "# Y = output = biocrude\n",
        "\n",
        "X = data.loc[:, :'Solvent']\n",
        "Y = data['Biocrude wt%']\n",
        "X = X.to_numpy()\n",
        "Y = Y.to_numpy().reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split into Training/Testing/Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 60% train, 20% test, 20% validation\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.20, random_state = 0)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape, '\\n')\n",
        "\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNEnoL15sHiM"
      },
      "source": [
        "### Normalize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCHuGVYIsJon"
      },
      "outputs": [],
      "source": [
        "X_normalizer = PowerTransformer()\n",
        "Y_normalizer = PowerTransformer()\n",
        "\n",
        "X_scaler = MinMaxScaler()\n",
        "Y_scaler = MinMaxScaler()\n",
        "\n",
        "# Yeo-Johnson Transformation\n",
        "x_train = X_normalizer.fit_transform(x_train)\n",
        "x_test = X_normalizer.fit_transform(x_test)\n",
        "y_train = Y_normalizer.fit_transform(y_train)\n",
        "y_test = Y_normalizer.fit_transform(y_test)\n",
        "\n",
        "# Min Max Scaler\n",
        "x_train = X_scaler.fit_transform(x_train)\n",
        "x_test = X_scaler.fit_transform(x_test)\n",
        "y_train = Y_scaler.fit_transform(y_train)\n",
        "y_test = Y_scaler.fit_transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYWqiEmQeacS"
      },
      "source": [
        "### Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "id": "0LD4XWFxeeKs",
        "outputId": "474b9850-b7c3-47d7-adaa-060ec107fe59"
      },
      "outputs": [],
      "source": [
        "matrix = data.corr(method = 'spearman')\n",
        "cmap = sns.diverging_palette(250, 15, s = 75, l = 40, n = 9, center = 'light', as_cmap = True)\n",
        "plt.figure(figsize = (12, 9))\n",
        "ax = sns.heatmap(matrix, center = 0, annot = True, fmt = '.2f', square = True, cmap = cmap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZM_waGKrt-G"
      },
      "source": [
        "# 4. Build Tensorflow Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chYFR2b41ouA"
      },
      "source": [
        "### Compile Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "keras.backend.clear_session()\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dense(1, activation = 'linear'))\n",
        "learning_rate = 0.001\n",
        "optimizer = Adam(learning_rate = learning_rate)\n",
        "loss = 'mean_squared_error'\n",
        "model.compile(optimizer = optimizer, loss = loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1Wu1zqkXew2"
      },
      "outputs": [],
      "source": [
        "def model_builder(hp):\n",
        "    model = Sequential()\n",
        "\n",
        "    hp_units_1 = hp.Int('hp_units_1', min_value = 1, max_value = 128)\n",
        "    hp_units_2 = hp.Int('hp_units_2', min_value = 1, max_value = 128)\n",
        "    hp_units_3 = hp.Int('hp_units_3', min_value = 1, max_value = 128)\n",
        "    hp_units_4 = hp.Int('hp_units_4', min_value = 1, max_value = 128)\n",
        "    hp_units_5 = hp.Int('hp_units_5', min_value = 1, max_value = 128)\n",
        "    hp_units_6 = hp.Int('hp_units_6', min_value = 1, max_value = 128)\n",
        "\n",
        "    model.add(Dense(hp_units_1, activation = 'relu'))\n",
        "    model.add(Dense(hp_units_2, activation = 'relu'))\n",
        "    model.add(Dense(hp_units_3, activation = 'relu'))\n",
        "    model.add(Dense(hp_units_4, activation = 'relu'))\n",
        "    model.add(Dense(hp_units_5, activation = 'relu'))\n",
        "    model.add(Dense(hp_units_6, activation = 'relu'))\n",
        "    model.add(Dense(1, activation = 'linear'))\n",
        "\n",
        "    hp_learning_rate = hp.Choice('hp_learning_rate', values = [0.01, 0.001, 0.0001])\n",
        "    hp_loss = hp.Choice('hp_loss', values = ['mean_squared_error', 'mean_absolute_error', 'huber'])\n",
        "\n",
        "    optimizer = Adam(learning_rate = hp_learning_rate)\n",
        "    model.compile(optimizer = optimizer, loss = hp_loss)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# tuner = kt.Hyperband(model_builder, objective = 'val_loss', max_epochs = 10, factor = 3, overwrite = True)\n",
        "# stop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5, restore_best_weights = True, start_from_epoch = 0)\n",
        "# tuner.search(x_train, y_train, epochs = 200, validation_data = (x_val, y_val), callbacks = [stop_early])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "# print(best_hps.get('hp_units_1'))\n",
        "# print(best_hps.get('hp_units_2'))\n",
        "# print(best_hps.get('hp_units_3'))\n",
        "# print(best_hps.get('hp_units_4'))\n",
        "# print(best_hps.get('hp_units_5'))\n",
        "# print(best_hps.get('hp_units_6'))\n",
        "# print(best_hps.get('hp_learning_rate'))\n",
        "# print(best_hps.get('hp_loss'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model = tuner.hypermodel.build(best_hps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SyoXdnt1_3j"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfyOsHHoiF0J",
        "outputId": "b36af9a4-159f-4149-999b-a5aa99f396b2"
      },
      "outputs": [],
      "source": [
        "num_epochs = 200\n",
        "history = model.fit(x_train, y_train, validation_split = 0.25, epochs = num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83IJ94Po2DOI"
      },
      "source": [
        "### Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGv9OssGi59Y",
        "outputId": "21d95a4d-96f5-4fdd-9c10-2202e7ebea05"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_test)\n",
        "print('Loss:\\t\\t', metrics.mean_squared_error(y_test, y_pred))\n",
        "print('R^2 Score: \\t', metrics.r2_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12AzyeEV8z20"
      },
      "source": [
        "### Perform Inverse Transformation of Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfsWzwUU868I"
      },
      "outputs": [],
      "source": [
        "y_test_inverse = Y_scaler.inverse_transform(y_test)\n",
        "y_test_inverse = Y_normalizer.inverse_transform(y_test_inverse)\n",
        "\n",
        "y_pred_inverse = Y_scaler.inverse_transform(y_pred)\n",
        "y_pred_inverse = Y_normalizer.inverse_transform(y_pred_inverse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XZBzH52xXCV"
      },
      "source": [
        "### Plot Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "mRhQbmX-xWmY",
        "outputId": "8eacff5c-2c5f-41be-9736-100033a3329f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (16, 6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss', fontsize = 20)\n",
        "plt.ylabel('Loss', fontsize = 18)\n",
        "plt.xlabel('Epoch', fontsize = 18)\n",
        "plt.yticks(np.arange(0, 0.05, step = 0.01))\n",
        "plt.xlim(0, num_epochs)\n",
        "plt.ylim(0, 0.05)\n",
        "plt.legend(['Training Loss', 'Validation Loss'], fontsize = 14, loc = 'upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5Vu18hkzRES"
      },
      "source": [
        "### Plot Biocrude Predicted vs Expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "t77hvsi_zQta",
        "outputId": "65b52f87-7bbc-4f15-9c08-d857b524afa0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (16, 6))\n",
        "plt.plot(y_test_inverse, color = \"blue\", label = 'Expected Output', marker = '.')\n",
        "plt.plot(y_pred_inverse, color = \"red\", label = 'Predicted Output', marker = '.')\n",
        "plt.legend(['Expected Output', 'Predicted Output'], fontsize = 12)\n",
        "plt.xlabel(\"Data\", fontsize = 20)\n",
        "plt.ylabel(\"Biocrude Yield (%)\", fontsize = 18)\n",
        "plt.xlim(0, len(y_test))\n",
        "plt.ylim(0, 100) \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJbF3LUFwwCa"
      },
      "source": [
        "### Plotting Cross-validation Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "WNsF22P9w5Zn",
        "outputId": "a79ca681-7811-42c9-d025-ce2cea505283"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
        "PredictionErrorDisplay.from_predictions(y_test_inverse, y_pred=y_pred_inverse, kind=\"actual_vs_predicted\", subsample=250, ax=axs[0], random_state=0)\n",
        "axs[0].set_title(\"Actual vs. Predicted values\")\n",
        "PredictionErrorDisplay.from_predictions(y_test_inverse, y_pred=y_pred_inverse, kind=\"residual_vs_predicted\", subsample=250, ax=axs[1], random_state=0)\n",
        "axs[1].set_title(\"Residuals vs. Predicted Values\")\n",
        "fig.suptitle(\"Plotting cross-validated predictions\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdliPXy0JpTl"
      },
      "source": [
        "### SHAP Explainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AsjRCO6IN8L",
        "outputId": "295191f4-af46-4b58-99b1-8121df97d79b"
      },
      "outputs": [],
      "source": [
        "feature_names = data.loc[:, :'Solvent'].columns\n",
        "explainer = shap.Explainer(model, x_train)\n",
        "shap_values = explainer(x_test)\n",
        "shap.summary_plot(shap_values, x_test, feature_names = feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIPwXPfwst3D"
      },
      "source": [
        "# 5. Build XGBoost Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7MxVwvsLzYu"
      },
      "source": [
        "### Build and Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a1Z7zuXss0q"
      },
      "outputs": [],
      "source": [
        "xgb_model = XGBRegressor()\n",
        "xgb_model.fit(x_train, y_train)\n",
        "y_pred = xgb_model.predict(x_test).reshape(-1, 1)\n",
        "xgb_model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOhyPiOVN0P6"
      },
      "source": [
        "### Perform Inverse Transformation of Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hS_dZfXbN1nD"
      },
      "outputs": [],
      "source": [
        "y_test_inverse = Y_scaler.inverse_transform(y_test)\n",
        "y_test_inverse = Y_normalizer.inverse_transform(y_test_inverse)\n",
        "\n",
        "y_pred_inverse = Y_scaler.inverse_transform(y_pred)\n",
        "y_pred_inverse = Y_normalizer.inverse_transform(y_pred_inverse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8ZL21fZNpTj"
      },
      "source": [
        "### Plot Biocrude Predicted vs Expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRsaiiYZNslw"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (16, 6))\n",
        "plt.plot(y_test_inverse, color = \"blue\", label = 'Expected Output', marker = '.')\n",
        "plt.plot(y_pred_inverse, color = \"red\", label = 'Predicted Output', marker = '.')\n",
        "plt.legend(['Expected Output', 'Predicted Output'], fontsize = 12)\n",
        "plt.xlabel(\"Data\", fontsize = 20)\n",
        "plt.ylabel(\"Biocrude Yield (%)\", fontsize = 18)\n",
        "plt.xlim(0, len(y_test))\n",
        "plt.ylim(0, 100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "416TsKBvL1VH"
      },
      "source": [
        "### SHAP Explainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed2nV2FKNbjp"
      },
      "outputs": [],
      "source": [
        "feature_names = data.loc[:, :'Solvent'].columns\n",
        "explainer = shap.Explainer(xgb_model, x_train)\n",
        "shap_values = explainer(x_test)\n",
        "shap.summary_plot(shap_values, x_test, feature_names = feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mq0XJp8oOb_z"
      },
      "source": [
        "# 6. Build Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5ghsJGfOlty"
      },
      "outputs": [],
      "source": [
        "linear_model = LinearRegression()\n",
        "linear_model.fit(x_train, y_train)\n",
        "y_pred = linear_model.predict(x_test)\n",
        "linear_model.score(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RtvyVs8PoGE"
      },
      "source": [
        "### Perform Inverse Transformation of Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzje3nKQPpf-"
      },
      "outputs": [],
      "source": [
        "y_test_inverse = Y_scaler.inverse_transform(y_test)\n",
        "y_test_inverse = Y_normalizer.inverse_transform(y_test_inverse)\n",
        "\n",
        "y_pred_inverse = Y_scaler.inverse_transform(y_pred)\n",
        "y_pred_inverse = Y_normalizer.inverse_transform(y_pred_inverse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUGObA2KPq0Z"
      },
      "source": [
        "### Plot Biocrude Predicted vs Expected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8mAA8iVPqnb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (16, 6))\n",
        "plt.plot(y_test_inverse, color = \"blue\", label = 'Expected Output', marker = '.')\n",
        "plt.plot(y_pred_inverse, color = \"red\", label = 'Predicted Output', marker = '.')\n",
        "plt.legend(['Expected Output', 'Predicted Output'], fontsize = 12)\n",
        "plt.xlabel(\"Data\", fontsize = 20)\n",
        "plt.ylabel(\"Biocrude Yield (%)\", fontsize = 18)\n",
        "plt.xlim(0, len(y_test))\n",
        "plt.ylim(0, 100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjUxFM3VTBHH"
      },
      "source": [
        "### SHAP Explainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Suy4_NEyTCjk"
      },
      "outputs": [],
      "source": [
        "feature_names = data.loc[:, :'Solvent'].columns\n",
        "explainer = shap.Explainer(linear_model, x_train)\n",
        "shap_values = explainer(x_test)\n",
        "shap.summary_plot(shap_values, x_test, feature_names = feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FX5MXADDqsp"
      },
      "source": [
        "# 7. Linear Regression Models Using Carbohydrate, Protein, Lipid, and Ash"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUu1qHuDJWeW"
      },
      "source": [
        "### Read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGcQ2P3fE0wy"
      },
      "outputs": [],
      "source": [
        "#Only including certain parameters\n",
        "columns_to_include1 = ['Carbohydrates wt%', 'Protein wt%', 'Lipids wt%', 'Biocrude wt%']\n",
        "columns_to_include2 = ['Carbohydrates wt%', 'Protein wt%', 'Lipids wt%', 'Ash wt%', 'Biocrude wt%']\n",
        "data1 = original_data[columns_to_include1]\n",
        "data2 = original_data[columns_to_include2]\n",
        "data1 = data1.dropna()\n",
        "data2 = data2.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYkpvgRoJz-B"
      },
      "source": [
        "### New pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7uIM9idKUUi"
      },
      "outputs": [],
      "source": [
        "#Split into training and testing datasets\n",
        "X_1 = data1.loc[:, :'Lipids wt%']\n",
        "Y_1 = data1['Biocrude wt%']\n",
        "X_1 = X_1.to_numpy()\n",
        "Y_1 = Y_1.to_numpy().reshape(-1, 1)\n",
        "\n",
        "#Split into training and testing datasets\n",
        "X_2 = data2.loc[:, :'Ash wt%']\n",
        "Y_2 = data2['Biocrude wt%']\n",
        "X_2 = X_2.to_numpy()\n",
        "Y_2 = Y_2.to_numpy().reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQ9H7aRJRCq9"
      },
      "outputs": [],
      "source": [
        "#Normalize datasets\n",
        "x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(X_1, Y_1, test_size = 0.25)\n",
        "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(X_2, Y_2, test_size = 0.25)\n",
        "\n",
        "X_normalizer = PowerTransformer()\n",
        "Y_normalizer = PowerTransformer()\n",
        "\n",
        "X_scaler = MinMaxScaler()\n",
        "Y_scaler = MinMaxScaler()\n",
        "\n",
        "# Yeo-Johnson Transformation\n",
        "#x_train = X_normalizer.fit_transform(x_train)\n",
        "#x_test = X_normalizer.fit_transform(x_test)\n",
        "#y_train = Y_normalizer.fit_transform(y_train)\n",
        "#y_test = Y_normalizer.fit_transform(y_test)\n",
        "\n",
        "# Min Max Scaler\n",
        "x_train_1 = X_scaler.fit_transform(x_train_1)\n",
        "x_test_1 = X_scaler.fit_transform(x_test_1)\n",
        "y_train_1 = Y_scaler.fit_transform(y_train_1)\n",
        "y_test_1 = Y_scaler.fit_transform(y_test_1)\n",
        "\n",
        "x_train_2 = X_scaler.fit_transform(x_train_2)\n",
        "x_test_2 = X_scaler.fit_transform(x_test_2)\n",
        "y_train_2 = Y_scaler.fit_transform(y_train_2)\n",
        "y_test_2 = Y_scaler.fit_transform(y_test_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_43QYEA2Qn0W"
      },
      "source": [
        "### Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs1GFh4wEofJ"
      },
      "outputs": [],
      "source": [
        "linear_model_1 = LinearRegression()\n",
        "linear_model_1.fit(x_train_1, y_train_1)\n",
        "y_pred_1 = linear_model_1.predict(x_test_1)\n",
        "print('linear_model_1 score: ', linear_model_1.score(x_test_1, y_test_1))\n",
        "\n",
        "linear_model_2 = LinearRegression()\n",
        "linear_model_2.fit(x_train_2, y_train_2)\n",
        "y_pred_2 = linear_model_2.predict(x_test_2)\n",
        "print('linear_model_2 score: ', linear_model_2.score(x_test_2, y_test_2))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
